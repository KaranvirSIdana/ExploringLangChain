{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt Templates Comparison\n",
        "Langchain Vs Vanilla Python"
      ],
      "metadata": {
        "id": "h3BbttP-h5P2"
      },
      "id": "h3BbttP-h5P2"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gcJ2cUocbaVk"
      },
      "outputs": [],
      "source": [
        "###########################Langchain############################\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "id": "gcJ2cUocbaVk"
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Summarize the following conversation between {customer_name} and the support agent.\n",
        "\n",
        "{extra_instruction}\n",
        "\n",
        "Transcript:\n",
        "{transcript}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "j9-FzKQgbz76"
      },
      "id": "j9-FzKQgbz76",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt ##So Prompt is basically an object that can have certain input variables. Thus we can dynamically and neatly introduce variables in this"
      ],
      "metadata": {
        "id": "6FylfQ5zcUdv",
        "outputId": "8ad79042-d7af-4d6b-c997-bb5092ce97ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6FylfQ5zcUdv",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['customer_name', 'extra_instruction', 'transcript'], input_types={}, partial_variables={}, template='\\nSummarize the following conversation between {customer_name} and the support agent.\\n\\n{extra_instruction}\\n\\nTranscript:\\n{transcript}\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "issue_type = 'billing'\n",
        "extra_instruction = (\n",
        "    \"Please priortize checking the cusomter's billing history\"\n",
        "    if issue_type == 'billing'\n",
        "    else \"Proceed with general troubleshooting\"\n",
        ")\n",
        "formatted_prompt =  prompt.format(\n",
        "    customer_name = \"Karan\",\n",
        "    transcript = \"Customer: I need help with my billing\\nAgent: Sure, let me check.\",\n",
        "    extra_instruction = extra_instruction)\n",
        "formatted_prompt"
      ],
      "metadata": {
        "id": "bBPyEqfeclso",
        "outputId": "61b98bf9-4149-40c7-80bb-0f08423f1264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "bBPyEqfeclso",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nSummarize the following conversation between Karan and the support agent.\\n\\nPlease priortize checking the cusomter's billing history\\n\\nTranscript:\\nCustomer: I need help with my billing\\nAgent: Sure, let me check.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################# Vanilla python#################################\n",
        "customer_name = \"Karan\"\n",
        "transcript = \"Customer: I need help with my billing\\nAgent: Sure, let me check.\"\n",
        "issue_type = \"billing\"\n",
        "\n",
        "# logic in Python\n",
        "if issue_type == \"billing\":\n",
        "    extra_instruction = \"Please prioritize checking the customer's billing history.\"\n",
        "else:\n",
        "    extra_instruction = \"Proceed with general troubleshooting.\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation between {customer_name} and the support agent.\n",
        "\n",
        "{extra_instruction}\n",
        "\n",
        "Transcript:\n",
        "{transcript}\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)\n"
      ],
      "metadata": {
        "id": "bR7QY80Wgqpl",
        "outputId": "e74e4b2c-6af3-41d7-e57b-b688bc0b84c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bR7QY80Wgqpl",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summarize the following conversation between Karan and the support agent.\n",
            "\n",
            "Please prioritize checking the customer's billing history.\n",
            "\n",
            "Transcript:\n",
            "Customer: I need help with my billing\n",
            "Agent: Sure, let me check.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Langchain code has few striking features\n",
        "*  Highly Modular\n",
        "*  Easy to Debug\n",
        "\n",
        "On the other hand, Vanilla python prompt templates, they lack modularity and you basically need to custom function to create templates.\n",
        "\n",
        "**Thus for production ready codes, Langchain is much better for production ready codes**\n"
      ],
      "metadata": {
        "id": "2e60u62kgra8"
      },
      "id": "2e60u62kgra8"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYLBc8epfTL-"
      },
      "id": "GYLBc8epfTL-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}